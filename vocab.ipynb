{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"vocab","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNkBZEldBTVZNWK0JtYvQu0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"AX1NyVczNx2k","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":141},"outputId":"619669ad-2580-417a-f16a-485349c2bdbf","executionInfo":{"status":"ok","timestamp":1591507146169,"user_tz":-330,"elapsed":35469,"user":{"displayName":"Sahasra Ranjan","photoUrl":"","userId":"00705869038433939548"}}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","%cd /content/gdrive/My\\ Drive/Colab/ITSP"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","/content/gdrive/My Drive/Colab/ITSP\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpk8aTOsNxmu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"edcd7d35-9274-4c39-d0d3-5c2f3d8d570e","executionInfo":{"status":"ok","timestamp":1591507160375,"user_tz":-330,"elapsed":4687,"user":{"displayName":"Sahasra Ranjan","photoUrl":"","userId":"00705869038433939548"}}},"source":["!ls"],"execution_count":8,"outputs":[{"output_type":"stream","text":["build_vocab.py\tdata.py      preprocess.ipynb  results\t    utils.py\n","ckpts\t\tevaluate.py  preprocess.py     train.ipynb  vocab.ipynb\n","data\t\tmodel\t     __pycache__       train.py\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"imQfg5nvLUG4","colab_type":"code","colab":{}},"source":["from os.path import join\n","import pickle as pkl\n","from collections import Counter\n","import argparse"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnljwfvrMkQE","colab_type":"code","colab":{}},"source":["START_TOKEN = 0\n","PAD_TOKEN = 1\n","END_TOKEN = 2\n","UNK_TOKEN = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iln-vEUTMltW","colab_type":"code","colab":{}},"source":["class Vocab(object):\n","    def __init__(self):\n","        self.sign2id = {\"<s>\": START_TOKEN, \"</s>\": END_TOKEN,\n","                        \"<pad>\": PAD_TOKEN, \"<unk>\": UNK_TOKEN}\n","        self.id2sign = dict((idx, token)\n","                            for token, idx in self.sign2id.items())\n","        self.length = 4\n","\n","    def add_sign(self, sign):\n","        if sign not in self.sign2id:\n","            self.sign2id[sign] = self.length\n","            self.id2sign[self.length] = sign\n","            self.length += 1\n","\n","    def __len__(self):\n","        return self.length"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mBV9GzdLMnN6","colab_type":"code","colab":{}},"source":["def build_vocab(data_dir, min_count=10):\n","    \"\"\"\n","    traverse training formulas to make vocab\n","    and store the vocab in the file\n","    \"\"\"\n","    vocab = Vocab()\n","    counter = Counter()\n","\n","    formulas_file = join(data_dir, 'im2latex_formulas.norm.lst')\n","    with open(formulas_file, 'r') as f:\n","        formulas = [formula.strip('\\n') for formula in f.readlines()]\n","\n","    with open(join(data_dir, 'im2latex_train_filter.lst'), 'r') as f:\n","        for line in f:\n","            _, idx = line.strip('\\n').split()\n","            idx = int(idx)\n","            formula = formulas[idx].split()\n","            counter.update(formula)\n","\n","    for word, count in counter.most_common():\n","        if count >= min_count:\n","            vocab.add_sign(word)\n","    vocab_file = join(data_dir, 'vocab.pkl')\n","    print(\"Writing Vocab File in \", vocab_file)\n","    with open(vocab_file, 'wb') as w:\n","        pkl.dump(vocab, w)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JdG3XGwHMqY0","colab_type":"code","colab":{}},"source":["def load_vocab(data_dir):\n","    with open(join(data_dir, 'vocab.pkl'), 'rb') as f:\n","        vocab = pkl.load(f)\n","    print(\"Load vocab including {} words!\".format(len(vocab)))\n","    return vocab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LQjWcUEaMsT1","colab_type":"code","colab":{}},"source":["data_path = \"./data/\"\n","\n","vocab = build_vocab(data_path)"],"execution_count":0,"outputs":[]}]}